{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 70203,
          "databundleVersionId": 8068726,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30684,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "notebooka3489e63aa",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jkranyak/birdscompetitionkaggle/blob/main/CRNN_Model_attempt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'birdclef-2024:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F70203%2F8068726%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240411%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240411T234502Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D46e0e22533c4fcd389c01d0e4a59680f0195c48981d89b38fbcc56169788c4e2ec0cd598173d4b060798187fc098d9ae8be44f928e19332fd7a04dd9291b7cd5812e6ccb7a55cde8fb478dd218fbb7838d1668800383c690cadf71fdb848aef8fc877fe66aa901c88f53b367b5159910d89ce41d7d6e5efaa398ab4edb3a3698eb791cf66685b93ce0b06ccbe72381b605d5a1cd8666e4a5b0c3deed470d2e40bcebf7459e89a08001c6c206049a51e26d8448f234521076fa17a96a87092b56e9f57708917dce91638fcc740d304c9522406f9230270c574117522f32a1760132f49b58bdb9ccae232fd02fe940370249bd14d548dc193e0be81f80f0badebf'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkagW9VijPL_",
        "outputId": "8496fdd7-da26-478e-bc5b-8129625d98df"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading birdclef-2024, 23390009647 bytes compressed\n",
            "[===============                                   ] 7374561280 bytes downloaded"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-04-11T23:32:49.552887Z",
          "iopub.execute_input": "2024-04-11T23:32:49.553549Z",
          "iopub.status.idle": "2024-04-11T23:32:55.164783Z",
          "shell.execute_reply.started": "2024-04-11T23:32:49.553516Z",
          "shell.execute_reply": "2024-04-11T23:32:55.163536Z"
        },
        "trusted": true,
        "id": "lu13AVocjPMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa soundfile tensorflow scikit-learn numpy pandas matplotlib seaborn tqdm\n",
        "!pip install audiomentations\n",
        "!pip install tqdm\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-11T23:35:59.34574Z",
          "iopub.execute_input": "2024-04-11T23:35:59.34623Z",
          "iopub.status.idle": "2024-04-11T23:36:42.312614Z",
          "shell.execute_reply.started": "2024-04-11T23:35:59.346192Z",
          "shell.execute_reply": "2024-04-11T23:36:42.311225Z"
        },
        "trusted": true,
        "id": "rUe5amTcjPMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import librosa\n",
        "import librosa.display\n",
        "import soundfile as sf\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, Flatten, LSTM, TimeDistributed, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-11T23:36:42.333826Z",
          "iopub.execute_input": "2024-04-11T23:36:42.334282Z",
          "iopub.status.idle": "2024-04-11T23:36:42.350386Z",
          "shell.execute_reply.started": "2024-04-11T23:36:42.334239Z",
          "shell.execute_reply": "2024-04-11T23:36:42.349414Z"
        },
        "trusted": true,
        "id": "K6oHmAOhjPMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "G5n082Z2yIID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define output directories\n",
        "output_directories = ['processed_data', 'models', 'submissions', 'visualizations']\n",
        "base_working_dir = '/kaggle/working/'\n",
        "\n",
        "# Creating subdirectories\n",
        "for directory in output_directories:\n",
        "    path = os.path.join(base_working_dir, directory)\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    print(f\"Created directory: {path}\")\n",
        "\n",
        "# Define base directories for input data\n",
        "base_input_dir = \"/kaggle/input/birdclef-2024\"\n",
        "\n",
        "# Paths for specific data types\n",
        "train_audio_base_path = os.path.join(base_input_dir, \"train_audio\")\n",
        "unlabeled_soundscapes_path = os.path.join(base_input_dir, \"unlabeled_soundscapes\")\n",
        "train_metadata_csv_path = os.path.join(base_input_dir, \"train_metadata.csv\")\n",
        "taxonomy_csv_path = os.path.join(base_input_dir, \"eBird_Taxonomy_v2021.csv\")\n",
        "sample_submission_csv_path = os.path.join(base_input_dir, \"sample_submission.csv\")\n",
        "test_soundscapes_path = os.path.join(base_input_dir, \"test_soundscapes\")\n",
        "\n",
        "# Function to list all audio files considering subdirectories\n",
        "def list_all_audio_files(base_path):\n",
        "    all_files = []\n",
        "    for root, dirs, files in os.walk(base_path):\n",
        "        for file in files:\n",
        "            if file.endswith('.ogg'):\n",
        "                all_files.append(os.path.join(root, file))\n",
        "    return all_files\n",
        "\n",
        "# Example usage\n",
        "all_train_audio_files = list_all_audio_files(train_audio_base_path)\n",
        "print(f\"Total audio files found: {len(all_train_audio_files)}\")\n"
      ],
      "metadata": {
        "id": "zRcUvdsrj_dP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Audio Processing and Spectrogram Generation\n",
        "\n",
        "In this section, we focus on converting raw audio data into a more visually interpretable form called a spectrogram, which is crucial for our Convolutional Recurrent Neural Network (CRNN) model. Spectrograms provide a 2D representation of the sound where the x-axis represents time, the y-axis represents frequency, and the intensity of colors shows the amplitude of a particular frequency at a particular time.\n",
        "\n",
        "#### Step-by-step Process:\n",
        "\n",
        "1. **Audio Loading**: Each audio file is loaded into the memory, which captures the sound's waveform as a time-series data.\n",
        "2. **Spectrogram Conversion**: The raw audio is then converted into a spectrogram using the Mel scale, which is more aligned with human auditory perception.\n",
        "3. **Visualization and Saving**: The generated spectrogram is visualized and saved as a PNG file. This image serves as the input to our neural network.\n",
        "\n",
        "The following visualization is an example of a spectrogram generated from our dataset. This particular audio file represents the call of a bird species recorded in the Western Ghats. By analyzing such images, our model learns to identify patterns specific to different bird calls.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9zRpCGT-1F0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of generating a spectrogram\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load an example audio file\n",
        "y, sr = librosa.load(librosa.ex('trumpet'))\n",
        "\n",
        "# Create a Mel-spectrogram\n",
        "S = librosa.feature.melspectrogram(y=y, sr=sr)\n",
        "S_DB = librosa.power_to_db(S, ref=np.max)\n",
        "\n",
        "# Plot the Mel-spectrogram\n",
        "plt.figure(figsize=(10, 4))\n",
        "librosa.display.specshow(S_DB, sr=sr, x_axis='time', y_axis='mel')\n",
        "plt.colorbar(format='%+2.0f dB')\n",
        "plt.title('Mel-frequency spectrogram')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R-5L2tXE3BYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "M5Spqb3p0ijM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the file path is correct and the file exists\n",
        "metadata_path = '/kaggle/input/birdclef-2024/train_metadata.csv'\n",
        "metadata = pd.read_csv(metadata_path)\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "display(metadata.head())\n",
        "\n",
        "# Display basic information about the dataframe\n",
        "print(metadata.info())"
      ],
      "metadata": {
        "id": "_5Zr59PZWfsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the metadata\n",
        "metadata_path = '/kaggle/input/birdclef-2024/train_metadata.csv'\n",
        "metadata = pd.read_csv(metadata_path)\n",
        "\n",
        "# Apply the expanded geographic filter for the Western Ghats and surrounding migratory areas\n",
        "western_ghats_birds = metadata[\n",
        "    (metadata['latitude'].between(8, 20)) &\n",
        "    (metadata['longitude'].between(72, 80))\n",
        "]\n",
        "\n",
        "# Handle missing values if necessary (drop or impute)\n",
        "western_ghats_birds = western_ghats_birds.dropna(subset=['latitude', 'longitude'])\n",
        "\n",
        "# Print the new DataFrame to verify the filter and see the first few rows\n",
        "print(western_ghats_birds.head())\n",
        "print(western_ghats_birds.info())\n",
        "\n",
        "# Optional: Save this DataFrame to a new CSV for easier access or further analysis\n",
        "output_path = '/kaggle/working/western_ghats_birds.csv'\n",
        "western_ghats_birds.to_csv(output_path, index=False)\n",
        "print(f\"DataFrame saved to {output_path}\")"
      ],
      "metadata": {
        "id": "Cr_EezENBPMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming df is already loaded\n",
        "df_path = '/kaggle/working/western_ghats_birds.csv'\n",
        "df = pd.read_csv(df_path)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df = df.drop(['author', 'license', 'rating', 'url', 'secondary_labels', 'type'], axis=1)\n",
        "\n",
        "# Optionally, save the trimmed DataFrame for further use\n",
        "trimmed_df_path = '/kaggle/working/western_ghats_birds_trimmed.csv'\n",
        "df.to_csv(trimmed_df_path, index=False)\n",
        "\n",
        "print(\"Trimmed DataFrame saved:\", trimmed_df_path)\n",
        "print(df.head())  # Show the first few entries of the trimmed DataFrame\n"
      ],
      "metadata": {
        "id": "-s9Ccjg0BT3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "\n",
        "base_audio_dir = '/kaggle/input/birdclef-2024/train_audio'\n",
        "\n",
        "def load_audio_data(row):\n",
        "    file_path = os.path.join(base_audio_dir, row['filename'])\n",
        "    audio, sr = librosa.load(file_path)\n",
        "    return audio, sr\n",
        "\n",
        "# Example of loading audio for the first few filtered entries\n",
        "for index, row in filtered_metadata.head().iterrows():\n",
        "    audio, sr = load_audio_data(row)\n",
        "    print(f\"Loaded audio from {row['filename']} with sample rate {sr}\")\n"
      ],
      "metadata": {
        "id": "RP_JqvKbBZWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "\n",
        "# Load the DataFrame\n",
        "df_path = '/kaggle/working/western_ghats_birds.csv'\n",
        "western_ghats_birds = pd.read_csv(df_path)\n",
        "\n",
        "# Base directory where original audio files are stored\n",
        "base_audio_dir = '/kaggle/input/birdclef-2024/train_audio'\n",
        "\n",
        "# Directory to store the copied audio files\n",
        "target_dir = '/kaggle/working/processed_embeddings/western_ghats_bird_calls'\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "# Initialize a counter for copied files\n",
        "files_copied = 0\n",
        "\n",
        "# Iterate through the DataFrame and copy files\n",
        "for idx, row in western_ghats_birds.iterrows():\n",
        "    src_path = os.path.join(base_audio_dir, row['filename'])\n",
        "    if os.path.exists(src_path):\n",
        "        # Ensure the target subdirectory exists\n",
        "        subfolder_path = os.path.join(target_dir, os.path.dirname(row['filename']))\n",
        "        os.makedirs(subfolder_path, exist_ok=True)\n",
        "\n",
        "        # Define the destination path\n",
        "        dest_path = os.path.join(target_dir, row['filename'])\n",
        "\n",
        "        # Copy the file, replacing it if it already exists\n",
        "        shutil.copy2(src_path, dest_path)  # Use copy2 for better handling of metadata and overwriting\n",
        "        files_copied += 1  # Increment the counter\n",
        "        print(f\"Copied and replaced if existing: {src_path} to {dest_path}\")\n",
        "    else:\n",
        "        print(f\"File not found: {src_path}\")\n",
        "\n",
        "# Print the total number of files copied\n",
        "print(f\"All specified audio files have been processed. Total files copied or replaced: {files_copied}\")\n"
      ],
      "metadata": {
        "id": "tOUnFGGkBdEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GRU, Dense, Flatten, TimeDistributed, Dropout\n",
        "\n",
        "def create_crnn_model(input_shape, number_of_classes):\n",
        "    \"\"\"Creates a Convolutional Recurrent Neural Network (CRNN) model.\n",
        "\n",
        "    Args:\n",
        "        input_shape (tuple): The shape of the input spectrogram (height, width, channels).\n",
        "        number_of_classes (int): The number of bird species to classify.\n",
        "\n",
        "    Returns:\n",
        "        A compiled Keras model.\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        # First conv layer\n",
        "        Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "\n",
        "        # Second conv layer\n",
        "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "\n",
        "        # Third conv layer\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "\n",
        "        # Fourth conv layer\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "\n",
        "        # Flatten the output to feed into the RNN\n",
        "        TimeDistributed(Flatten()),\n",
        "\n",
        "        # Recurrent layer\n",
        "        GRU(128, return_sequences=True),\n",
        "        Dropout(0.5),\n",
        "        GRU(128),\n",
        "\n",
        "        # Output layer\n",
        "        Dense(number_of_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Example usage\n",
        "input_shape = (128, 128, 1)  # Adjust as per the spectrogram dimensions\n",
        "number_of_classes = 264  # Example: number of bird species\n",
        "model = create_crnn_model(input_shape, number_of_classes)\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "QBzpSwQ9DbZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the metadata\n",
        "metadata_path = '/kaggle/working/western_ghats_birds.csv'\n",
        "metadata = pd.read_csv(metadata_path)\n",
        "\n",
        "extra_data_path = '/kaggle/input/birdclef-2024/eBird_Taxonomy_v2021.csv'\n",
        "extra_data = pd.read_csv(extra_data_path)\n",
        "\n",
        "# Display basic info and the first few rows of the DataFrame\n",
        "print(metadata.info())\n",
        "print(metadata.head())\n",
        "print(extra_data.info())\n",
        "print(extra_data.head())\n",
        "\n",
        "# Analyze the distribution of the 'primary_label' to understand class balance\n",
        "print(metadata['primary_label'].value_counts())\n",
        "\n",
        "sample_audio_path_full = f\"/kaggle/working/processed_embeddings/western_ghats_bird_calls/{metadata.loc[0, 'filename']}\"\n",
        "\n",
        "# Load and display a sample audio file\n",
        "audio_data, sample_rate = librosa.load(sample_audio_path_full)\n",
        "\n",
        "# Plot the waveform\n",
        "plt.figure(figsize=(10, 4))\n",
        "librosa.display.waveshow(y=audio_data, sr=sample_rate)\n",
        "plt.title('Waveform of a Sample Audio File')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.show()\n",
        "\n",
        "# Plot the spectrogram\n",
        "S = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate, n_fft=2048, hop_length=512, n_mels=128)\n",
        "S_DB = librosa.power_to_db(S=S, ref=np.max)\n",
        "plt.figure(figsize=(10, 4))\n",
        "librosa.display.specshow(S_DB, sr=sample_rate, x_axis='time', y_axis='mel')\n",
        "plt.colorbar(format='%+2.0f dB')\n",
        "plt.title('Mel-frequency spectrogram of the Sample Audio')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c0N2l4EVEm0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the metadata from CSV\n",
        "metadata_path = '/kaggle/working/western_ghats_birds.csv'\n",
        "metadata = pd.read_csv(metadata_path)\n",
        "\n",
        "# Filter metadata for high-quality audio files (ratings 4 or higher)\n",
        "high_quality_audio = metadata[metadata['rating'] >= 4.0]\n",
        "\n",
        "# Save filtered metadata to a new CSV for easy access and record keeping\n",
        "filtered_metadata_path = '/kaggle/working/high_quality_western_ghats_birds.csv'\n",
        "high_quality_audio.to_csv(filtered_metadata_path, index=False)\n"
      ],
      "metadata": {
        "id": "xqp3dKK4G-fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def generate_and_save_spectrogram(audio_path, output_path, target_size=(128, 128)):\n",
        "    # Load the audio file with librosa\n",
        "    y, sr = librosa.load(path=audio_path, sr=None)\n",
        "    # Generate the Mel spectrogram with all arguments specified as keywords\n",
        "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=512, n_mels=128)\n",
        "    # Convert the power spectrogram to decibel units, fully keyworded\n",
        "    S_DB = librosa.power_to_db(S=S, ref=np.max)\n",
        "    # Normalize the spectrogram to 0-255 and convert to image\n",
        "    img = Image.fromarray(np.uint8((S_DB - S_DB.min()) / (S_DB.max() - S_DB.min()) * 255))\n",
        "    img = img.resize(target_size)\n",
        "    img.save(output_path)\n",
        "\n",
        "def process_audio_files(metadata_df, base_dir, output_dir):\n",
        "    # Ensure the base output directory exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Process each file in the DataFrame\n",
        "    for _, row in metadata_df.iterrows():\n",
        "        # Construct the full path for each audio file\n",
        "        audio_path = os.path.join(base_dir, row['filename'])\n",
        "        if os.path.exists(audio_path):\n",
        "            # Create the subdirectory structure within the output directory\n",
        "            subfolder_path = os.path.join(output_dir, os.path.dirname(row['filename']))\n",
        "            os.makedirs(subfolder_path, exist_ok=True)\n",
        "\n",
        "            # Construct the output path with the correct file extension\n",
        "            output_path = os.path.join(subfolder_path, os.path.splitext(os.path.basename(row['filename']))[0] + '.png')\n",
        "            generate_and_save_spectrogram(audio_path, output_path)\n",
        "\n",
        "# Define directories\n",
        "base_audio_dir = '/kaggle/working/processed_embeddings/western_ghats_bird_calls'\n",
        "output_spectrogram_dir = '/kaggle/working/spectrograms'\n",
        "\n",
        "# Process high-quality audio files\n",
        "process_audio_files(high_quality_audio, base_audio_dir, output_spectrogram_dir)\n"
      ],
      "metadata": {
        "id": "lEsbg0DKJGv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming the filtered metadata was saved correctly\n",
        "filtered_metadata_path = '/kaggle/working/high_quality_western_ghats_birds.csv'\n",
        "\n",
        "# Load filtered high-quality metadata\n",
        "filtered_metadata = pd.read_csv(filtered_metadata_path)\n",
        "\n",
        "# Display the distribution of primary labels\n",
        "label_counts = filtered_metadata['primary_label'].value_counts()\n",
        "print(\"Distribution of bird species (primary labels):\")\n",
        "print(label_counts)\n",
        "\n",
        "# Plotting the distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "label_counts.plot(kind='bar')\n",
        "plt.title('Distribution of Bird Species in High-Quality Audio Files')\n",
        "plt.xlabel('Bird Species')\n",
        "plt.ylabel('Counts')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "nKDM7VycJJ3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gPVteBOzKP5i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}